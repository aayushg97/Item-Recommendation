{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 05:00:07.091068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 05:00:07.660401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-30 05:00:07.660441: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-30 05:00:07.720335: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-30 05:00:09.913767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-30 05:00:09.914072: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-30 05:00:09.914088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N\n",
    "\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r\n",
    "\n",
    "# Some data structures that will be useful\n",
    "\n",
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "\n",
    "random.shuffle(allRatings)\n",
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data set for read task\n",
    "readValid = []\n",
    "readTrain = []\n",
    "readBooksPerUser = defaultdict(set)\n",
    "allBooks = set()\n",
    "\n",
    "for user, book, _ in allRatings:\n",
    "    allBooks.add(book)\n",
    "    readBooksPerUser[user].add(book)\n",
    "\n",
    "# Construct training set\n",
    "for user, book, _ in ratingsTrain:\n",
    "    readTrain.append([user, book, 1])\n",
    "\n",
    "    # Randomly sample a book not read by user\n",
    "    randomBook = book\n",
    "    while(randomBook in readBooksPerUser[user]):\n",
    "        randomBook = random.sample(allBooks, 1)[0]\n",
    "        \n",
    "    readTrain.append([user, randomBook, 0])\n",
    "    \n",
    "# Construct validation set\n",
    "for user, book, _ in ratingsValid:\n",
    "    readValid.append([user, book, 1])\n",
    "\n",
    "    # Randomly sampling a book not read by user\n",
    "    randomBook = book\n",
    "    while(randomBook in readBooksPerUser[user]):\n",
    "        randomBook = random.sample(allBooks, 1)[0]\n",
    "        \n",
    "    readValid.append([user, randomBook, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a6f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine most popular books\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "# Sort based on popularity\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "# Utility data structures\n",
    "booksPerUser = defaultdict(set)\n",
    "usersPerBook = defaultdict(set)\n",
    "\n",
    "for u,b,_ in ratingsTrain:\n",
    "    booksPerUser[u].add(b)\n",
    "    usersPerBook[b].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4a006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute jaccard similarity\n",
    "def Jaccard(set1, set2):\n",
    "    denom = len(set1.union(set2))\n",
    "    numer = len(set1.intersection(set2))\n",
    "    \n",
    "    if(denom == 0):\n",
    "        return 0\n",
    "    \n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad02e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9257526315789474\n",
      "0.6365\n"
     ]
    }
   ],
   "source": [
    "# Construct set of Popular books\n",
    "popularBooks = set()\n",
    "count = 0\n",
    "popThreshold = 0.75\n",
    "bookJaccardThreshold = 0.003\n",
    "userJaccardThreshold = 0.25\n",
    "\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    popularBooks.add(i)\n",
    "    if (count > popThreshold*totalRead): \n",
    "        break\n",
    "        \n",
    "# Construct feature vector\n",
    "def GetFeatureVector(u, b):\n",
    "    featVec = []\n",
    "    bookSimList = []\n",
    "    userSimList = []\n",
    "    \n",
    "    for otherBook in booksPerUser[u]:\n",
    "        if(otherBook == b):\n",
    "            continue\n",
    "            \n",
    "        bookSimList.append(Jaccard(usersPerBook[b], usersPerBook[otherBook]))\n",
    "        \n",
    "    for otherUser in usersPerBook[b]:\n",
    "        if(otherUser == u):\n",
    "            continue\n",
    "            \n",
    "        userSimList.append(Jaccard(booksPerUser[u], booksPerUser[otherUser]))\n",
    "    \n",
    "#     if(len(bookSimList)==0):\n",
    "#         featVec.extend([0, 0])\n",
    "#     else:\n",
    "#         featVec.extend([sum(bookSimList)/len(bookSimList), max(bookSimList)])\n",
    "        \n",
    "    featVec.append(sum((np.array(bookSimList) > bookJaccardThreshold).astype(int)))\n",
    "        \n",
    "#     if(len(userSimList)==0):\n",
    "#         featVec.extend([0, 0])\n",
    "#     else:\n",
    "#         featVec.extend([sum(userSimList)/len(userSimList), max(userSimList)])\n",
    "\n",
    "    featVec.append(sum((np.array(userSimList) > userJaccardThreshold).astype(int)))\n",
    "        \n",
    "    featVec.append(int(b in popularBooks))\n",
    "        \n",
    "    return featVec\n",
    "        \n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for u,b,l in readTrain:\n",
    "    X.append(GetFeatureVector(u, b))\n",
    "    Y.append(l)\n",
    "    \n",
    "# for u, b, l in readValid:\n",
    "#     X.append(GetFeatureVector(u,b))\n",
    "#     Y.append(l)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# print(np.mean(X[:,1]))\n",
    "# print(np.mean(X[:,2]))\n",
    "# meanVec = np.mean(X, axis=0)\n",
    "# stdVec = np.std(X, axis=0)\n",
    "# X = (X - meanVec)/stdVec\n",
    "\n",
    "readModel = linear_model.LogisticRegression(C=1.0, class_weight='balanced', max_iter=5000).fit(X,Y)\n",
    "   \n",
    "# Compute accuracy on training set\n",
    "accTrain = sum((Y - readModel.predict(X) == 0).astype(int))/len(Y)\n",
    "print(accTrain)\n",
    "    \n",
    "# Compute accuracy on validation set\n",
    "Xvalid = []\n",
    "Yvalid = []\n",
    "\n",
    "for u, b, l in readValid:\n",
    "    Xvalid.append(GetFeatureVector(u,b))\n",
    "    Yvalid.append(l)\n",
    "\n",
    "Xvalid = np.array(Xvalid)\n",
    "Yvalid = np.array(Yvalid)\n",
    "#Xvalid = (Xvalid - meanVec)/stdVec\n",
    "\n",
    "acc = sum((Yvalid - readModel.predict(Xvalid) == 0).astype(int))/len(Yvalid)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "testDict = defaultdict(list)\n",
    "# testList = []\n",
    "# Xtest = []\n",
    "\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    \n",
    "    testDict[u].append(b)\n",
    "\n",
    "for usr in testDict:\n",
    "    bookList = testDict[usr]\n",
    "    Xtest = [GetFeatureVector(usr,bk) for bk in bookList]\n",
    "    scoreList = readModel.predict_proba(Xtest)[:,1]\n",
    "    combList = list(zip(scoreList, bookList))\n",
    "    combList.sort(reverse=True)\n",
    "    half1 = combList[:int(len(combList)/2)]\n",
    "    half2 = combList[int(len(combList)/2):]\n",
    "    for scr, bk in half1:\n",
    "        predictions.write(usr+\",\"+bk+\",\"+\"1\\n\")\n",
    "        \n",
    "    for scr, bk in half2:\n",
    "        predictions.write(usr+\",\"+bk+\",\"+\"0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
